# LangMask

> **æ³¨æ„**: ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å¤±æ•—ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦çµ‚äº†ã—ã¾ã—ãŸã€‚
> 
> å¤±æ•—ã®ä¸»ãªç†ç”±ï¼š
> 1. ãƒ†ã‚¹ãƒˆã‚’é‡è¦–ã—ã™ããŸã“ã¨ã§ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ä»¥ä¸Šã«è¤‡é›‘åŒ–ã—ã¦ã—ã¾ã„ã¾ã—ãŸã€‚
> 2. `model`ã¨`masker`ã®è¨­è¨ˆãŒé©åˆ‡ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚HuggingFaceã®`LogitsProcessor`ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç°¡æ½”ã«åŒæ§˜ã®æ©Ÿèƒ½ã‚’å®Ÿè£…ã§ãã‚‹ã“ã¨ãŒåˆ¤æ˜ã—ã¾ã—ãŸã€‚
>
> ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ä»Šå¾Œã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã•ã‚Œã¾ã™ã€‚

[![PyPI version](https://badge.fury.io/py/langmask.svg)](https://badge.fury.io/py/langmask)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Documentation Status](https://readthedocs.org/projects/langmask/badge/?version=latest)](https://langmask.readthedocs.io/en/latest/?badge=latest)

LangMaskï¼ˆãƒ©ãƒ³ã‚°ãƒã‚¹ã‚¯ï¼‰ã¯å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®å‡ºåŠ›è¨€èªã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã®Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚Qwenã‚„Llamaãªã©ã®å¤šè¨€èªãƒ¢ãƒ‡ãƒ«ã§ã‚‚ã€ç‰¹å®šã®è¨€èªã ã‘ã§å¿œç­”ã™ã‚‹ã‚ˆã†åˆ¶å¾¡ã§ãã¾ã™ã€‚

## ä¸»ãªæ©Ÿèƒ½

- ğŸŒ è¤‡æ•°è¨€èªã®ã‚µãƒãƒ¼ãƒˆï¼ˆæ—¥æœ¬èªã€è‹±èªã€ä¸­å›½èªã€éŸ“å›½èªã€ãƒ•ãƒ©ãƒ³ã‚¹èªãªã©ï¼‰
- ğŸ”„ å‹•çš„ãªè¨€èªåˆ‡ã‚Šæ›¿ãˆï¼ˆå®Ÿè¡Œæ™‚ã«å‡ºåŠ›è¨€èªã‚’å¤‰æ›´å¯èƒ½ï¼‰
- ğŸ›ï¸ èª¿æ•´å¯èƒ½ãªãƒã‚¹ã‚­ãƒ³ã‚°å¼·åº¦ï¼ˆã‚½ãƒ•ãƒˆã‹ã‚‰ãƒãƒ¼ãƒ‰ã¾ã§ï¼‰
- ğŸ“Š è©³ç´°ãªãƒˆãƒ¼ã‚¯ãƒ³åˆ†é¡ã¨å¯è¦–åŒ–
- ğŸš€ Hugging Faceãƒ¢ãƒ‡ãƒ«ã¨ã®ç°¡å˜ãªçµ±åˆ
- ğŸ”Œ æ¨™æº–çš„ãªHugging Faceã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨ã®å®Œå…¨ãªäº’æ›æ€§

## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# uvã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆåˆå›ã®ã¿ï¼‰
curl -LsSf https://astral.sh/uv/install.sh | sh

# æ–¹æ³•1: PyPIã‹ã‚‰ã®å®‰å®šç‰ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv add langmask

# æ–¹æ³•2: GitHubã‹ã‚‰ã®æœ€æ–°ç‰ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
uv add git+https://github.com/Hajime-Y/langmask.git

# æ–¹æ³•3: é–‹ç™ºç”¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼å‘ã‘ï¼‰
git clone https://github.com/Hajime-Y/langmask.git
cd langmask
uv sync --extra dev
```

## ä½¿ç”¨ä¾‹

### åŸºæœ¬çš„ãªä½¿ã„æ–¹

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from langmask import MultilingualLanguageModel

# ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®æº–å‚™
base_model = AutoModelForCausalLM.from_pretrained("Qwen/Qwen-7B-Chat")
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen-7B-Chat")

# è¨€èªåˆ¶å¾¡ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆæ—¥æœ¬èªã®ã¿ã‚’è¨±å¯ï¼‰
model = MultilingualLanguageModel(
    model=base_model,
    tokenizer=tokenizer,
    allowed_languages=["JA"],
    mask_strength=0.9
)

# ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
inputs = tokenizer(["AIã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„"], return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=200)

# å…¥åŠ›ã‚’é™¤ã„ãŸç”Ÿæˆéƒ¨åˆ†ã®ã¿ã‚’å–å¾—
generated_ids = [
    output_ids[len(input_ids):] 
    for input_ids, output_ids in zip(inputs.input_ids, outputs)
]

# ãƒ‡ã‚³ãƒ¼ãƒ‰
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
```

### è¤‡æ•°è¨€èªã®åŒæ™‚è¨±å¯

```python
# æ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ã‚’è¨±å¯
model = MultilingualLanguageModel(
    model=base_model,
    tokenizer=tokenizer,
    allowed_languages=["JA", "EN"]
)

# è‹±èªæ··ã˜ã‚Šã®æ—¥æœ¬èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã‚‚ã€æ—¥æœ¬èªã¨è‹±èªã®å¿œç­”ãŒå¯èƒ½
inputs = tokenizer(["AIã®æœªæ¥ã«ã¤ã„ã¦explainã—ã¦ãã ã•ã„ã€‚"], return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_new_tokens=200)
generated_ids = [
    output_ids[len(input_ids):] 
    for input_ids, output_ids in zip(inputs.input_ids, outputs)
]
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(response)
```

### å‹•çš„ãªè¨€èªåˆ‡ã‚Šæ›¿ãˆ

```python
# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ï¼ˆæœ€åˆã¯æ—¥æœ¬èªã®ã¿ï¼‰
model = MultilingualLanguageModel(
    model=base_model,
    tokenizer=tokenizer,
    allowed_languages=["JA"]
)

# æ—¥æœ¬èªã§ã®å¿œç­”
ja_inputs = tokenizer(["AIã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„"], return_tensors="pt").to(model.device)
ja_outputs = model.generate(**ja_inputs, max_new_tokens=200)

# è‹±èªã«åˆ‡ã‚Šæ›¿ãˆ
model.set_languages(["EN"])
en_inputs = tokenizer(["Explain about AI"], return_tensors="pt").to(model.device)
en_outputs = model.generate(**en_inputs, max_new_tokens=200)

# æ—¥æœ¬èªã¨è‹±èªã®ä¸¡æ–¹ã‚’è¨±å¯
model.set_languages(["JA", "EN"])
mixed_inputs = tokenizer(["AIã«ã¤ã„ã¦explainã—ã¦ãã ã•ã„"], return_tensors="pt").to(model.device)
mixed_outputs = model.generate(**mixed_inputs, max_new_tokens=200)
```

### ãƒã‚¹ã‚­ãƒ³ã‚°å¼·åº¦ã®èª¿æ•´

```python
# ã‚½ãƒ•ãƒˆãƒã‚¹ã‚­ãƒ³ã‚°ï¼ˆä»–ã®è¨€èªã‚‚å°‘ã—æ··ã–ã‚‹å¯èƒ½æ€§ã‚ã‚Šï¼‰
model.set_mask_strength(0.7)

# å¼·ã‚ã®ã‚½ãƒ•ãƒˆãƒã‚¹ã‚­ãƒ³ã‚°ï¼ˆã»ã¨ã‚“ã©æŒ‡å®šè¨€èªã®ã¿ï¼‰
model.set_mask_strength(0.95)

# ãƒãƒ¼ãƒ‰ãƒã‚¹ã‚­ãƒ³ã‚°ï¼ˆæŒ‡å®šè¨€èªã®ã¿ã‚’å¼·åˆ¶ï¼‰
model.set_mask_strength(1.0)
```

### ãƒˆãƒ¼ã‚¯ãƒ³åˆ†é¡ã®ç¢ºèª

```python
# ãƒ†ã‚­ã‚¹ãƒˆå†…ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨€èªã”ã¨ã«åˆ†é¡
stats = model.debug_token_classification(
    "ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼Hello, World! ä½ å¥½ï¼Œä¸–ç•Œï¼",
    tokenizer=tokenizer,
    verbose=True  # è©³ç´°å‡ºåŠ›
)

# çµæœï¼ˆä¾‹ï¼‰:
# JA (Japanese) ãƒˆãƒ¼ã‚¯ãƒ³: 4 (40.0%)
# EN (English) ãƒˆãƒ¼ã‚¯ãƒ³: 4 (40.0%)
# ZH (Chinese) ãƒˆãƒ¼ã‚¯ãƒ³: 2 (20.0%)
```

## å¯¾å¿œè¨€èª

ç¾åœ¨ã€ä»¥ä¸‹ã®è¨€èªã«å¯¾å¿œã—ã¦ã„ã¾ã™ï¼š

| è¨€èªã‚³ãƒ¼ãƒ‰ | è¨€èªå |
|------------|--------|
| JA | æ—¥æœ¬èª (Japanese) |
| EN | è‹±èª (English) |
| ZH | ä¸­å›½èª (Chinese) |
| KO | éŸ“å›½èª (Korean) |
| FR | ãƒ•ãƒ©ãƒ³ã‚¹èª (French) |
| DE | ãƒ‰ã‚¤ãƒ„èª (German) |
| ES | ã‚¹ãƒšã‚¤ãƒ³èª (Spanish) |
| IT | ã‚¤ã‚¿ãƒªã‚¢èª (Italian) |
| RU | ãƒ­ã‚·ã‚¢èª (Russian) |
| PT | ãƒãƒ«ãƒˆã‚¬ãƒ«èª (Portuguese) |

## ä»•çµ„ã¿

LangMaskã¯ã€LLMã®ç”Ÿæˆéç¨‹ã§logitsã¨å‘¼ã°ã‚Œã‚‹æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºç‡åˆ†å¸ƒã‚’æ“ä½œã—ã¾ã™ã€‚

1. ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆæ™‚ã€ãƒ¢ãƒ‡ãƒ«ã¯å„ãƒˆãƒ¼ã‚¯ãƒ³ã®é¸æŠç¢ºç‡ã‚’è¨ˆç®—ã—ã¾ã™ï¼ˆlogitsï¼‰
2. LangMaskã¯æŒ‡å®šã•ã‚ŒãŸè¨€èªä»¥å¤–ã®ãƒˆãƒ¼ã‚¯ãƒ³ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’é©ç”¨ã—ã¾ã™
3. ãƒšãƒŠãƒ«ãƒ†ã‚£ã®å¼·ã•ã¯mask_strengthãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§èª¿æ•´ã§ãã¾ã™
4. è¨€èªåˆ¤å®šã¯äº‹å‰ã«è§£æã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³åˆ†é¡ã«åŸºã¥ã„ã¦è¡Œã‚ã‚Œã¾ã™

ã“ã®æ–¹æ³•ã«ã‚ˆã‚Šã€ãƒ¢ãƒ‡ãƒ«ã®å†…éƒ¨ã‚’ä¿®æ­£ã™ã‚‹ã“ã¨ãªãã€å‡ºåŠ›è¨€èªã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚

## è²¢çŒ®æ–¹æ³•

ãƒã‚°å ±å‘Šã€æ©Ÿèƒ½ãƒªã‚¯ã‚¨ã‚¹ãƒˆã€ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ­“è¿ã—ã¾ã™ï¼

1. ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯ã—ã¾ã™
2. æ–°ã—ã„ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆã—ã¾ã™ (`git checkout -b feature/amazing-feature`)
3. é–‹ç™ºç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™:
   ```bash
   git clone https://github.com/Hajime-Y/langmask.git
   cd langmask
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   curl -LsSf https://astral.sh/uv/install.sh | sh  # uvã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
   uv sync --extra dev  # é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
   ```
4. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆã—ã¾ã™ (`git commit -m 'Add some amazing feature'`)
5. ãƒ–ãƒ©ãƒ³ãƒã‚’ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã™ (`git push origin feature/amazing-feature`)
6. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™

## ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

Apache License 2.0ã®ä¸‹ã§é…å¸ƒã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯[LICENSE](LICENSE)ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚

## å¼•ç”¨

ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç ”ç©¶ã§ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ä»¥ä¸‹ã®å½¢å¼ã§å¼•ç”¨ã—ã¦ãã ã•ã„ï¼š

```
@software{langmask2025,
  author = {Hajime Yagihara},
  title = {LangMask: A Library for Controlling Output Languages in Large Language Models},
  year = {2025},
  url = {https://github.com/Hajime-Y/langmask}
}
```

## ä»Šå¾Œã®äºˆå®š

- ã‚ˆã‚Šå¤šãã®è¨€èªã®ã‚µãƒãƒ¼ãƒˆ
- ã‚ˆã‚Šé«˜åº¦ãªè¨€èªåˆ¤å®šã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
- ç‰¹å®šã®å°‚é–€åˆ†é‡å‘ã‘ã®å˜èªãƒªã‚¹ãƒˆ
- WebUIãƒ‡ãƒ¢ã®ä½œæˆ
- ãƒˆãƒ¼ã‚¯ãƒ³å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã®å¼·åŒ–

---

**å…è²¬äº‹é …**: ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯å®Ÿé¨“çš„ãªãƒ„ãƒ¼ãƒ«ã§ã‚ã‚Šã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã‚„ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã§å®Œç’§ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç‰¹ã«å°‚é–€ç”¨èªã‚„å›ºæœ‰åè©ãªã©ã§ã¯æƒ³å®šé€šã‚Šã®çµæœã«ãªã‚‰ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚